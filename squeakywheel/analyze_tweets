#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Sep 24 15:25:02 2018

@author: rcarns
"""

import keras
import nltk
import pandas as pd
import numpy as np
import re
import codecs
import textblob
import seaborn as sns
from matplotlib import pyplot as plt
import warnings
from nltk.tokenize import RegexpTokenizer

#sklearn

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.decomposition import PCA, TruncatedSVD
import matplotlib
import matplotlib.patches as mpatches
from matplotlib import pyplot as plt
from sklearn import cluster, datasets, mixture 
from sklearn.neighbors import kneighbors_graph 
from sklearn.preprocessing import StandardScaler 
from itertools import cycle, islice
from sklearn.decomposition import PCA, TruncatedSVD
import matplotlib
import matplotlib.patches as mpatches
from matplotlib import pyplot as plt
from sklearn.cluster import MiniBatchKMeans

# Gensim
import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel

import random

plt.close('all')

warnings.filterwarnings("ignore",category=DeprecationWarning)
warnings.filterwarnings("ignore",category=UserWarning)


train_tweets = pd.read_csv('train_tweets.csv')
apple_tweets = train_tweets[train_tweets['source'].isin(['@@Apple','@@AppleSupport'])]
#train_tweets = apple_tweets

train_tweets = (train_tweets.drop_duplicates(subset='text'))





#    
#
#tokenizer = RegexpTokenizer(r'\w+')
#train_tweets.loc[:,"tokens"] = train_tweets.loc[:,"text"].apply(tokenizer.tokenize)
#
#data_words = train_tweets['tokens'][:]
#
#
## Build the bigram and trigram models
#bigram = gensim.models.Phrases(data_words, min_count=5, threshold=5) # higher threshold fewer phrases.
#trigram = gensim.models.Phrases(bigram[data_words], threshold=5)  
#
## Faster way to get a sentence clubbed as a trigram/bigram
#bigram_mod = gensim.models.phrases.Phraser(bigram)
#trigram_mod = gensim.models.phrases.Phraser(trigram)
#
## See trigram example
#print(trigram_mod[bigram_mod[data_words[0:10]]])
#
#def make_bigrams(texts):
#    return [bigram_mod[doc] for doc in texts]
#
#def make_trigrams(texts):
#    return [trigram_mod[bigram_mod[doc]] for doc in texts]
#
#train_tweets['tokens'] = trigram_mod[bigram_mod[train_tweets['tokens']]]
#
#train_tweets['tokens'][:10]
#train_tweets['trigram_text'] = train_tweets['tokens'].apply(' '.join)
#train_tweets['trigram_text'][:10]
#
## Import stopwords with scikit-learn
#from sklearn.feature_extraction import text
#stop = text.ENGLISH_STOP_WORDS.union(['amp','via','i_m','it_s'])
#train_tweets['trigram_text'] = train_tweets['trigram_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))

# randomize training and test corps

train_tweets['trigram_text'] = train_tweets['processed_text']
train_tweets = train_tweets.dropna('rows',subset=['trigram_text'])

train_to_test_ratio = 4
CorpTwitters = pd.read_csv('CorpTwittersAll.csv',names=['Main','Support','Sector'])
#CorpTwitters = CorpTwitters[(CorpTwitters['Sector'].isin(['retail','delivery','web']))]

#ComplaintAccounts = CorpTwitters['Support'].apply(lambda x: x[1:].lower())
#MainAccounts = CorpTwitters['Main'].apply(lambda x: x[1:].lower())
CorpTwitters = CorpTwitters.iloc[:-1,:]
CorpTwitters['Main'] = CorpTwitters['Main'].str.lower()
CorpTwitters['Support'] = CorpTwitters['Support'].str.lower()
CorpTwitters['Main'] = CorpTwitters['Main'].str.replace('@\ ?@?','')
CorpTwitters['Support'] = CorpTwitters['Support'].str.replace('@\ ?@?','')



ntests = len(CorpTwitters)//train_to_test_ratio
ntrain = len(CorpTwitters)-ntests
randdex = random.sample(range(len(CorpTwitters)),ntests)
CorpArray = np.array(CorpTwitters)
TestTwitters = CorpArray[randdex,:]
TestTwitters = np.reshape(TestTwitters[:,:2],ntests*2)
mask = np.ones(len(CorpArray), dtype=bool)
mask[randdex] = False
TrainTwitters = CorpArray[mask,:]
TrainTwitters = np.reshape(TrainTwitters[:,:2],ntrain*2)


standard_sets = False
single_source = False
if standard_sets == True:
    TestTwitters = ['target',
 'asktarget',
 'honda',
 'hondacustsvc',
 'dropbox',
 'dropboxsupport',
 'ford',
 'fordservice',
 'dell',
 'dellcares']
    TrainTwitters = ['walmart',
 'walmarthelp',
 'amazon',
 'amazonhelp',
 'microsoft',
 'microsofthelps',
 'fedex',
 'fedexhelp',
 'ups',
 'upshelp',
 'usps',
 'uspshelp',
 'linkedin',
 'linkedinhelp',
 'comcast',
 'comcastcares',
 'americanexpress',
 'askamex',
 'mastercard',
 'askmastercard',
 'visa',
 'askvisa',
 'spotify',
 'spotifycares',
 'nike',
 'nikesupport',
 'steam_games',
 'steamsupport']








#train_tweets = train_tweets[~train_tweets['source'].isin(['@Apple','@AppleSupport'])]


def train_vectorize(tweetframe):
    tweet_corpus = train_tweets["trigram_text"].tolist()
    tfidf_vectorizer = TfidfVectorizer(token_pattern=r"(?u)\S\S+")
    tfidf_vectorizer.fit(tweet_corpus)

    return tfidf_vectorizer

def get_xy(subframe,vectorizer):
    X = vectorizer.transform(subframe['trigram_text'].tolist())
    y = subframe['class_label'].tolist()
    return X,y

tfidf_vectorizer = train_vectorize(train_tweets)


if single_source == True:
    X,y = get_xy(train_tweets,tfidf_vectorizer)
    X_train_counts,X_test_counts,y_train,y_test = train_test_split(X,y)
    
elif single_source==False:
    print(TestTwitters)
    print(TrainTwitters)
    # the \ ? in the string replace accounts for a typo in the list of corps
    train_tweets['source'] = train_tweets['source'].str.replace('@\ ?@?','')
    train_tweets['source'] = train_tweets['source'].str.lower()
    train_tweets = train_tweets.dropna('rows',subset=['trigram_text'])
    
    test_tweet_frame = train_tweets[(train_tweets['source'].str.lower()).isin(TestTwitters)]
    train_tweet_frame = train_tweets[(train_tweets['source'].str.lower()).isin(TrainTwitters)]
    
    [X_train_counts,y_train] = get_xy(train_tweet_frame,tfidf_vectorizer)
    [X_test_counts,y_test] = get_xy(test_tweet_frame,tfidf_vectorizer)








def plot_LSA(test_data, test_labels, savepath="PCA_demo.csv", plot=True):
        lsa = TruncatedSVD(n_components=2)
        lsa.fit(test_data)
        lsa_scores = lsa.transform(test_data)
        color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}
        color_column = [color_mapper[label] for label in test_labels]
        print(color_column[:5])
        print(test_labels[:5])
        colors = ['orange','blue','blue']
        if plot:
            plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=color_column, cmap=matplotlib.colors.ListedColormap(colors))
            red_patch = mpatches.Patch(color='orange', label='Neutral')
            green_patch = mpatches.Patch(color='blue', label='Complaint')
            plt.legend(handles=[red_patch, green_patch], prop={'size': 30})


#fig = plt.figure(figsize=(16, 16))          
#plot_LSA(X_train_counts, y_train)
#plt.show()
model_list = []

from sklearn.linear_model import LogisticRegression
modelname = 'Logistic Regression'
print(modelname)
clf = LogisticRegression(C=1.0, penalty='l2',class_weight='balanced', solver='liblinear', 
                          multi_class='ovr', random_state=40)
clf.fit(X_train_counts, y_train)
#model_list.append([modelname,clf])

from sklearn.metrics import roc_curve,roc_auc_score
y_proba = clf.predict_proba(X_test_counts)[:,1]
##Computing false and true positive rates
fpr, tpr, thresholds=roc_curve(y_test,y_proba)

import matplotlib.pyplot as plt
plt.figure()
##Adding the ROC
plt.plot(fpr, tpr, color='red',
 lw=2, label='ROC curve')
##Random FPR and TPR
plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')
##Title and label
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.show()
#print(thresholds)
print('ROC score is:')
print(roc_auc_score(clf.predict(X_test_counts),y_test))


from sklearn.metrics import average_precision_score
average_precision = average_precision_score(y_test, y_proba)

print('Average precision-recall score: {0:0.2f}'.format(
      average_precision))

from sklearn.metrics import precision_recall_curve
from sklearn.utils.fixes import signature

precision, recall, _ = precision_recall_curve(y_test, y_proba)

# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument
step_kwargs = ({'step': 'post'}
               if 'step' in signature(plt.fill_between).parameters
               else {})
plt.step(recall, precision, color='b', alpha=0.2,
         where='post')
plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(
          average_precision))




#from sklearn.naive_bayes import MultinomialNB
#modelname = 'Naive Bayes'
#print(modelname)
##from sklearn.svm import SVC
#clf = MultinomialNB().fit(X_train_counts, y_train)
##clf = SVC(kernel='linear').fit(X_train_counts, y_train)
#model_list.append([modelname,clf])


#modelname = 'Gradient Boosted Regression'
#print(modelname)
#from sklearn import ensemble
#params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,
#          'learning_rate': 0.01, 'loss': 'ls'}
#clf = ensemble.GradientBoostingRegressor(**params)
#
#clf.fit(X_train_counts, y_train)
#
#model_list.append([modelname,clf])

#from sklearn.ensemble import RandomForestClassifier
#modelname = 'Random Forest'
#print(modelname)
#clf = RandomForestClassifier(max_depth=2, random_state=0)
#clf.fit(X_train_counts, y_train)
#
#model_list.append([modelname,clf])

#from sklearn.metrics import confusion_matrix
#confusion_matrix = confusion_matrix(y_test, y_predicted_counts)
#confusion_matrix

def plot_conmat(confusion_matrix):
    import seaborn as sn
    import matplotlib.pyplot as plt
    #cmap='binary' switch to make it BW
    fig,ax = plt.subplots(figsize=[10,10])
    sn.set(font_scale=3)#for label size
    sn.heatmap(confusion_matrix, annot=True,annot_kws={"size": 25},fmt='g', cmap='Blues',
               xticklabels=['Neutral','Complaint'],yticklabels=['Neutral','Complaint'],
              cbar=False,vmin=0,ax=ax)# font size)
    plt.ylabel('Actual', fontsize=40)
    plt.xlabel('Predicted', fontsize=40)
#plot_conmat(confusion_matrix)

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report

def get_metrics(y_test, y_predicted):  
    # true positives / (true positives+false positives)
    precision = precision_score(y_test, y_predicted, pos_label=None,
                                    average='weighted')             
    # true positives / (true positives + false negatives)
    recall = recall_score(y_test, y_predicted, pos_label=None,
                              average='weighted')
    
    # harmonic mean of precision and recall
    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')
    
    # true positives + true negatives/ total
    accuracy = accuracy_score(y_test, y_predicted)
    return accuracy, precision, recall, f1

y_predicted_counts = clf.predict(X_test_counts)

accuracy, precision, recall, f1 = get_metrics(y_test, y_predicted_counts)
print("accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f" % (accuracy, precision, recall, f1))

for name,clf in model_list:
    print(name)
    y_predicted_counts = clf.predict(X_test_counts)
    accuracy, precision, recall, f1 = get_metrics(y_test, y_predicted_counts)

    print("accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f" % (accuracy, precision, recall, f1))
    




#Extracting the top 20 most influencial features (aka words) from the model:
def show_most_informative_features(vect, clf, n=20):
    feature_names = vect.get_feature_names()
    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))
    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])
    for (coef_1, fn_1), (coef_2, fn_2) in top:
        print("\t%.4f\t%-15s\t\t%.4f\t%-15s" % (coef_1, fn_1, coef_2, fn_2))
        
model= clf
vect = tfidf_vectorizer
feature_names = vect.get_feature_names()
        # loop for each class
classes ={}
n = 15
for class_index in range(model.coef_.shape[0]):
    word_importances = [(el, feature_names[i]) for i,el in enumerate(model.coef_[class_index])]
    sorted_coeff = sorted(word_importances, key = lambda x : x[0], reverse=True)
    tops = sorted(sorted_coeff[:n], key = lambda x : x[0])
    bottom = sorted_coeff[-n:]
    classes[class_index] = {
        'tops':tops,
        'bottom':bottom
    }

importance = classes

top_scores = [11-a[0] for a in importance[0]['tops']]
top_words = [a[1] for a in importance[0]['tops']]
bottom_scores = [11-a[0] for a in importance[0]['bottom']]
bottom_words = [a[1] for a in importance[0]['bottom']]

def plot_important_words(top_scores, top_words, bottom_scores, bottom_words,name):
    y_pos = np.arange(len(top_words))
    top_pairs = [(a,b) for a,b in zip(top_words, top_scores)]
    top_pairs = sorted(top_pairs, key=lambda x: x[1])

    bottom_pairs = [(a,b) for a,b in zip(bottom_words, bottom_scores)]
    bottom_pairs = sorted(bottom_pairs, key=lambda x: x[1], reverse=True)

    top_words = [a[0] for a in top_pairs]
    top_scores = [a[1] for a in top_pairs]

    bottom_words = [a[0] for a in bottom_pairs]
    bottom_scores = [a[1] for a in bottom_pairs]

    fig,ax = plt.subplots(figsize=(8,10))  
    
    #plt.subplot(111)
    sns.set_style('dark')
    ax.barh(y_pos,top_scores, align='center',alpha=0.3,color='#0066ff')
    #plt.title('Helpful', fontsize=20)
    plt.yticks(y_pos, top_words, fontsize=25)
    
    #plt.title(name, fontsize=20)
    ax.set_xticklabels([])
    plt.subplots_adjust(left=0.6)
    plt.show()


plot_important_words(top_scores, top_words, bottom_scores, bottom_words,'Important Features')


#print(TestTwitters)
#print(TrainTwitters)
show_most_informative_features(tfidf_vectorizer, clf, n=20)


#random_state = 1
#n_clusters = 5
#import matplotlib.colors as colors
#colors_={'tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'}
#mbk = MiniBatchKMeans(n_clusters=n_clusters, random_state=random_state).fit(y_train)
#for this_centroid, k, col in zip(mbk.cluster_centers_,
#                     range(n_clusters), colors_):
#    #print(col)
#    mask = mbk.labels_ == k
#    plt.scatter(lsa_scores[mask, 0], lsa_scores[mask, 1], c=col)
    


#from sklearn.svm import SVC
#clf = SVC(gamma=1, C=1,probability=True)
#clf.fit(X_train_counts,y_train)
#y_predicted_counts = clf.predict(X_test_counts)
#y_proba = clf.predict_proba(X_test_counts)[:,1]


