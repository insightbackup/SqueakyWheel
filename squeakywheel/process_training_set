#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Sep 18 13:40:18 2018

@author: rcarns
"""
import tweepy
import pandas as pd
import numpy as np
import pickle
from connections import twitterapi, postgresconnect


# get names of corporate twitters
CorpTwitters = pd.read_csv('CorpTwittersAll.txt',names=['Main','Support','Sector'])
ComplaintAccounts = CorpTwitters['Support'].apply(lambda x: x[1:].lower())
MainAccounts = CorpTwitters['Main'].apply(lambda x: x[1:].lower())
'''
# open file with stored tweets and read into dataframe
complaintpickle = open('complainttweets.dat','rb')
complaintweets = pickle.load(complaintpickle)
complaintpickle.close()
complainfilename = 'complaintweets.txt'
columns=['text','mentions','choose_one','class_label']
complaintframe = pd.DataFrame(columns=columns,index=range(len(complaintweets)))
i = 0
#with open(complainfilename,'w') as complainfile:
for tweet in complaintweets:
    tweettext = tweet['full_text']
    complaintframe.at[i,'text']=tweettext
    complaintframe.at[i,'mentions'] = tweet['entities']['user_mentions']
    complaintframe.at[i,'choose_one']='complaint'
    complaintframe.at[i,'class_label']=1
    i+=1
        
neutralpickle = open('neutraltweets.dat','rb')
neutraltweets = pickle.load(neutralpickle)
neutralpickle.close()
neutralfilename = 'neutraltweets.txt'
neutralframe = pd.DataFrame(columns=columns,index=range(len(neutraltweets)))
i=0
#with open(neutralfilename,'w') as neutralfile:
for tweet in neutraltweets:
        isComplaint=False
        for mention in tweet['entities']['user_mentions']:
            if mention['screen_name'].lower() in ComplaintAccounts:
                isComplaint=True
        if isComplaint==False:
            tweettext = tweet['full_text']
            neutralframe.at[i,'text']=tweettext
            neutralframe.at[i,'mentions'] = tweet['entities']['user_mentions']
            neutralframe.at[i,'choose_one']='neutral'
            neutralframe.at[i,'class_label']=0
            
            i+=1
'''
# get latest complaint tweet file
import glob
import os
complaintfilelist = glob.glob("./complaint*")
latest_complaint_file = max(complaintfilelist, key=os.path.getctime)

with open (latest_complaint_file,'rb') as picklefile:
    complaintframe = pickle.load(picklefile)
    
neutralfilelist = glob.glob("./neutral*")
latest_neutral_file = max(neutralfilelist, key=os.path.getctime)
with open(latest_neutral_file,'rb') as picklefile:
    neutralframe = pickle.load(picklefile)



def clean_text(df,text_field):     
    # taken from 'How to Solve 90% of NLP Problems' 
    # remove links     
    df[text_field] = df[text_field].str.replace(r"http\S+", "")
    df[text_field] = df[text_field].str.replace(r"http", "")
    # remove @ mentions
    df[text_field] = df[text_field].str.replace(r"@\S+", "")
    #remove hashtags
    df[text_field] = df[text_field].str.replace(r"#\S+", "")
    #remove weird characters
    df[text_field] = df[text_field].str.replace(r"[^A-Za-z0-9(),!?@\'\`\"\_\n\(\)]", " ")
    df[text_field] = df[text_field].str.replace(r"@", "at")
    df[text_field] = df[text_field].str.lower()
    df = df.fillna('')
    return df
    
train_tweets = pd.concat([complaintframe,neutralframe],0)
train_tweets = train_tweets.reset_index(drop=True)
train_tweets = clean_text(train_tweets,'text')
train_tweets = train_tweets.dropna('rows','any')
train_tweets.to_csv('train_tweets.csv')
    
    
    
    
    
    
    
    